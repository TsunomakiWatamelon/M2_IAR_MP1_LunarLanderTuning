{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzL7Hq-yjfcC",
        "outputId": "f6223fcf-9fc0-4fe9-f0bd-8db1fec45ac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium==0.28.1\n",
            "  Downloading gymnasium-0.28.1-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1) (1.26.4)\n",
            "Collecting jax-jumpy>=1.0.0 (from gymnasium==0.28.1)\n",
            "  Downloading jax_jumpy-1.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium==0.28.1)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: farama-notifications, jax-jumpy, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.28.1 jax-jumpy-1.0.0\n",
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.3.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.4.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.7.1)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2024.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable_baselines3) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable_baselines3) (1.3.0)\n",
            "Downloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stable_baselines3\n",
            "Successfully installed stable_baselines3-2.3.2\n",
            "Collecting swig\n",
            "  Downloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.6 kB)\n",
            "Downloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.2.1\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.26.4)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pygame==2.1.3 (from gymnasium[box2d])\n",
            "  Downloading pygame-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.2.1)\n",
            "Downloading pygame-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2376096 sha256=750a557288e5b11a11dd95c2f8fd4887dea526b17742c8fd15bca01865fc9435\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py, pygame\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.6.1\n",
            "    Uninstalling pygame-2.6.1:\n",
            "      Successfully uninstalled pygame-2.6.1\n",
            "Successfully installed box2d-py-2.3.5 pygame-2.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install \"gymnasium==0.28.1\"\n",
        "!pip install stable_baselines3\n",
        "!pip install swig\n",
        "!pip install gymnasium[box2d]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from stable_baselines3 import TD3\n",
        "from stable_baselines3.common import results_plotter\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.results_plotter import load_results, ts2xy, plot_results\n",
        "from stable_baselines3.common.noise import NormalActionNoise\n",
        "from stable_baselines3.common.callbacks import BaseCallback"
      ],
      "metadata": {
        "id": "Ym5GRlSxjurA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMVeassYu6R5",
        "outputId": "3ebff973-86e8-48a1-8cf8-6f595d6a4895"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TD3 on LunarLanderContinuous-v2 with stable_baselines3"
      ],
      "metadata": {
        "id": "eFzDo2lgk4rE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
        "    \"\"\"\n",
        "    Callback for saving a model based on the training reward\n",
        "    and tracking the actor losses, critic losses, and rewards per step.\n",
        "\n",
        "    :param check_freq: Frequency to check and save model.\n",
        "    :param log_dir: Directory to save the model.\n",
        "    :param verbose: Verbosity level.\n",
        "    \"\"\"\n",
        "    def __init__(self, check_freq: int, log_dir: str, verbose: int = 1):\n",
        "        super(SaveOnBestTrainingRewardCallback, self).__init__(verbose)\n",
        "        self.check_freq = check_freq\n",
        "        self.log_dir = log_dir\n",
        "        self.save_path = os.path.join(log_dir, \"best_model\")\n",
        "        self.best_mean_reward = -np.inf\n",
        "        self.actor_losses = []\n",
        "        self.critic_losses = []\n",
        "        self.rewards_per_step = []\n",
        "        self.episode_reward = 0\n",
        "        self.num_steps_in_episode = 0\n",
        "\n",
        "    def _init_callback(self) -> None:\n",
        "        if self.save_path is not None:\n",
        "            os.makedirs(self.save_path, exist_ok=True)\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        # Get the current reward from 'infos'\n",
        "        reward = self.locals['rewards'][0]  # Reward for the current step\n",
        "        self.episode_reward += reward\n",
        "        self.num_steps_in_episode += 1\n",
        "\n",
        "        # Record reward per step\n",
        "        self.rewards_per_step.append(reward)\n",
        "\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "            # Retrieve the training reward (mean reward of the last 100 steps)\n",
        "            x, y = ts2xy(load_results(self.log_dir), \"timesteps\")\n",
        "            if len(x) > 0:\n",
        "                mean_reward = np.mean(y[-100:])\n",
        "                if self.verbose >= 1:\n",
        "                    print(f\"Num timesteps: {self.num_timesteps}\")\n",
        "                    print(f\"Best mean reward: {self.best_mean_reward:.2f} - Last mean reward per step: {mean_reward:.2f}\")\n",
        "\n",
        "                # Save model if a new best reward is found\n",
        "                if mean_reward > self.best_mean_reward:\n",
        "                    self.best_mean_reward = mean_reward\n",
        "                    if self.verbose >= 1:\n",
        "                        print(f\"Saving new best model to {self.save_path}\")\n",
        "                    self.model.save(self.save_path)\n",
        "\n",
        "        # Access and log losses from the logger dictionary\n",
        "        self.actor_losses.append(self.logger.name_to_value['train/actor_loss'])\n",
        "        self.critic_losses.append(self.logger.name_to_value['train/critic_loss'])\n",
        "\n",
        "        return True"
      ],
      "metadata": {
        "id": "QWKBQhAukOEZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "seeds = [1,2,3,4,5]\n",
        "callbacks = []\n",
        "log_dirs = []\n",
        "models = []\n",
        "\n",
        "for seed in seeds:\n",
        "    # Set log directory\n",
        "    log_dir = f\"tmp{seed}/\"\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "    # Create and wrap the environment\n",
        "    env = gym.make(\"LunarLanderContinuous-v2\")\n",
        "    env.reset(seed=seed)\n",
        "    env = Monitor(env, log_dir)\n",
        "\n",
        "    # Add action noise for exploration\n",
        "    n_actions = env.action_space.shape[-1]\n",
        "    action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
        "\n",
        "    # Initialize model\n",
        "    model = TD3(\"MlpPolicy\", env, action_noise=action_noise, verbose=0, device=\"cuda\")\n",
        "\n",
        "    # Create callback to save model and track losses\n",
        "    callback = SaveOnBestTrainingRewardCallback(check_freq=1000, log_dir=log_dir)\n",
        "\n",
        "    callbacks.append(callback)\n",
        "    log_dirs.append(log_dir)\n",
        "    models.append(model)\n",
        "\n",
        "    # Train the model\n",
        "    timesteps = 1e5\n",
        "    model.learn(total_timesteps=int(timesteps), callback=callback)\n",
        "\n",
        "    # Stocker les résultats de l'entraînement pour cette seed\n",
        "    results = {\n",
        "        \"actor_losses\": [float(loss) for loss in callback.actor_losses],\n",
        "        \"critic_losses\": [float(loss) for loss in callback.critic_losses],\n",
        "        \"rewards_per_step\": [float(reward) for reward in callback.rewards_per_step],\n",
        "    }\n",
        "\n",
        "    # Sauvegarde des résultats dans un fichier JSON après chaque seed\n",
        "    with open(f\"training_results_seed{seed}.json\", \"w\") as f:\n",
        "        json.dump(results, f, indent=4)\n",
        "\n",
        "    print(f\"Les résultats de l'entraînement pour seed={seed} ont été enregistrés dans training_results_seed{seed}.json.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9UnEt-okPn2",
        "outputId": "b48ba03c-f74a-4968-aad4-8d7ef1068bf8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num timesteps: 1000\n",
            "Best mean reward: -inf - Last mean reward per step: -545.48\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 2000\n",
            "Best mean reward: -545.48 - Last mean reward per step: -429.08\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 3000\n",
            "Best mean reward: -429.08 - Last mean reward per step: -396.68\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 4000\n",
            "Best mean reward: -396.68 - Last mean reward per step: -377.72\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 5000\n",
            "Best mean reward: -377.72 - Last mean reward per step: -371.27\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 6000\n",
            "Best mean reward: -371.27 - Last mean reward per step: -358.07\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 7000\n",
            "Best mean reward: -358.07 - Last mean reward per step: -347.85\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 8000\n",
            "Best mean reward: -347.85 - Last mean reward per step: -336.57\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 9000\n",
            "Best mean reward: -336.57 - Last mean reward per step: -327.49\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 10000\n",
            "Best mean reward: -327.49 - Last mean reward per step: -311.51\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 11000\n",
            "Best mean reward: -311.51 - Last mean reward per step: -304.84\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 12000\n",
            "Best mean reward: -304.84 - Last mean reward per step: -298.38\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 13000\n",
            "Best mean reward: -298.38 - Last mean reward per step: -290.97\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 14000\n",
            "Best mean reward: -290.97 - Last mean reward per step: -285.32\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 15000\n",
            "Best mean reward: -285.32 - Last mean reward per step: -282.02\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 16000\n",
            "Best mean reward: -282.02 - Last mean reward per step: -276.87\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 17000\n",
            "Best mean reward: -276.87 - Last mean reward per step: -270.91\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 18000\n",
            "Best mean reward: -270.91 - Last mean reward per step: -259.52\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 19000\n",
            "Best mean reward: -259.52 - Last mean reward per step: -261.56\n",
            "Num timesteps: 20000\n",
            "Best mean reward: -259.52 - Last mean reward per step: -258.66\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 21000\n",
            "Best mean reward: -258.66 - Last mean reward per step: -252.95\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 22000\n",
            "Best mean reward: -252.95 - Last mean reward per step: -238.74\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 23000\n",
            "Best mean reward: -238.74 - Last mean reward per step: -240.56\n",
            "Num timesteps: 24000\n",
            "Best mean reward: -238.74 - Last mean reward per step: -241.91\n",
            "Num timesteps: 25000\n",
            "Best mean reward: -238.74 - Last mean reward per step: -238.11\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 26000\n",
            "Best mean reward: -238.11 - Last mean reward per step: -237.11\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 27000\n",
            "Best mean reward: -237.11 - Last mean reward per step: -239.64\n",
            "Num timesteps: 28000\n",
            "Best mean reward: -237.11 - Last mean reward per step: -236.16\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 29000\n",
            "Best mean reward: -236.16 - Last mean reward per step: -234.99\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 30000\n",
            "Best mean reward: -234.99 - Last mean reward per step: -230.23\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 31000\n",
            "Best mean reward: -230.23 - Last mean reward per step: -226.94\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 32000\n",
            "Best mean reward: -226.94 - Last mean reward per step: -225.90\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 33000\n",
            "Best mean reward: -225.90 - Last mean reward per step: -227.47\n",
            "Num timesteps: 34000\n",
            "Best mean reward: -225.90 - Last mean reward per step: -227.74\n",
            "Num timesteps: 35000\n",
            "Best mean reward: -225.90 - Last mean reward per step: -225.74\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 36000\n",
            "Best mean reward: -225.74 - Last mean reward per step: -222.82\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 37000\n",
            "Best mean reward: -222.82 - Last mean reward per step: -223.92\n",
            "Num timesteps: 38000\n",
            "Best mean reward: -222.82 - Last mean reward per step: -221.73\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 39000\n",
            "Best mean reward: -221.73 - Last mean reward per step: -207.65\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 40000\n",
            "Best mean reward: -207.65 - Last mean reward per step: -207.01\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 41000\n",
            "Best mean reward: -207.01 - Last mean reward per step: -206.27\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 42000\n",
            "Best mean reward: -206.27 - Last mean reward per step: -205.01\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 43000\n",
            "Best mean reward: -205.01 - Last mean reward per step: -196.91\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 44000\n",
            "Best mean reward: -196.91 - Last mean reward per step: -195.21\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 45000\n",
            "Best mean reward: -195.21 - Last mean reward per step: -189.50\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 46000\n",
            "Best mean reward: -189.50 - Last mean reward per step: -183.99\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 47000\n",
            "Best mean reward: -183.99 - Last mean reward per step: -180.02\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 48000\n",
            "Best mean reward: -180.02 - Last mean reward per step: -178.26\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 49000\n",
            "Best mean reward: -178.26 - Last mean reward per step: -173.98\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 50000\n",
            "Best mean reward: -173.98 - Last mean reward per step: -172.48\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 51000\n",
            "Best mean reward: -172.48 - Last mean reward per step: -171.44\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 52000\n",
            "Best mean reward: -171.44 - Last mean reward per step: -170.74\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 53000\n",
            "Best mean reward: -170.74 - Last mean reward per step: -169.73\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 54000\n",
            "Best mean reward: -169.73 - Last mean reward per step: -164.27\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 55000\n",
            "Best mean reward: -164.27 - Last mean reward per step: -163.49\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 56000\n",
            "Best mean reward: -163.49 - Last mean reward per step: -159.75\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 57000\n",
            "Best mean reward: -159.75 - Last mean reward per step: -156.02\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 58000\n",
            "Best mean reward: -156.02 - Last mean reward per step: -155.71\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 59000\n",
            "Best mean reward: -155.71 - Last mean reward per step: -155.13\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 60000\n",
            "Best mean reward: -155.13 - Last mean reward per step: -153.85\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 61000\n",
            "Best mean reward: -153.85 - Last mean reward per step: -152.27\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 62000\n",
            "Best mean reward: -152.27 - Last mean reward per step: -151.79\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 63000\n",
            "Best mean reward: -151.79 - Last mean reward per step: -151.25\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 64000\n",
            "Best mean reward: -151.25 - Last mean reward per step: -150.91\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 65000\n",
            "Best mean reward: -150.91 - Last mean reward per step: -149.75\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 66000\n",
            "Best mean reward: -149.75 - Last mean reward per step: -143.06\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 67000\n",
            "Best mean reward: -143.06 - Last mean reward per step: -124.30\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 68000\n",
            "Best mean reward: -124.30 - Last mean reward per step: -118.93\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 69000\n",
            "Best mean reward: -118.93 - Last mean reward per step: -99.00\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 70000\n",
            "Best mean reward: -99.00 - Last mean reward per step: -95.42\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 71000\n",
            "Best mean reward: -95.42 - Last mean reward per step: -83.79\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 72000\n",
            "Best mean reward: -83.79 - Last mean reward per step: -74.34\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 73000\n",
            "Best mean reward: -74.34 - Last mean reward per step: -68.78\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 74000\n",
            "Best mean reward: -68.78 - Last mean reward per step: -65.50\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 75000\n",
            "Best mean reward: -65.50 - Last mean reward per step: -61.66\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 76000\n",
            "Best mean reward: -61.66 - Last mean reward per step: -59.73\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 77000\n",
            "Best mean reward: -59.73 - Last mean reward per step: -57.14\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 78000\n",
            "Best mean reward: -57.14 - Last mean reward per step: -51.28\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 79000\n",
            "Best mean reward: -51.28 - Last mean reward per step: -42.14\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 80000\n",
            "Best mean reward: -42.14 - Last mean reward per step: -37.72\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 81000\n",
            "Best mean reward: -37.72 - Last mean reward per step: -36.33\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 82000\n",
            "Best mean reward: -36.33 - Last mean reward per step: -32.49\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 83000\n",
            "Best mean reward: -32.49 - Last mean reward per step: -33.16\n",
            "Num timesteps: 84000\n",
            "Best mean reward: -32.49 - Last mean reward per step: -22.16\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 85000\n",
            "Best mean reward: -22.16 - Last mean reward per step: -19.29\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 86000\n",
            "Best mean reward: -19.29 - Last mean reward per step: -9.18\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 87000\n",
            "Best mean reward: -9.18 - Last mean reward per step: -3.27\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 88000\n",
            "Best mean reward: -3.27 - Last mean reward per step: 1.05\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 89000\n",
            "Best mean reward: 1.05 - Last mean reward per step: 4.08\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 90000\n",
            "Best mean reward: 4.08 - Last mean reward per step: 10.21\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 91000\n",
            "Best mean reward: 10.21 - Last mean reward per step: 11.85\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 92000\n",
            "Best mean reward: 11.85 - Last mean reward per step: 16.54\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 93000\n",
            "Best mean reward: 16.54 - Last mean reward per step: 24.88\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 94000\n",
            "Best mean reward: 24.88 - Last mean reward per step: 26.28\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 95000\n",
            "Best mean reward: 26.28 - Last mean reward per step: 26.03\n",
            "Num timesteps: 96000\n",
            "Best mean reward: 26.28 - Last mean reward per step: 27.44\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 97000\n",
            "Best mean reward: 27.44 - Last mean reward per step: 34.47\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 98000\n",
            "Best mean reward: 34.47 - Last mean reward per step: 34.20\n",
            "Num timesteps: 99000\n",
            "Best mean reward: 34.47 - Last mean reward per step: 37.29\n",
            "Saving new best model to tmp1/best_model\n",
            "Num timesteps: 100000\n",
            "Best mean reward: 37.29 - Last mean reward per step: 40.91\n",
            "Saving new best model to tmp1/best_model\n",
            "Les résultats de l'entraînement pour seed=1 ont été enregistrés dans training_results_seed1.json.\n",
            "Num timesteps: 1000\n",
            "Best mean reward: -inf - Last mean reward per step: -1190.72\n",
            "Saving new best model to tmp2/best_model\n",
            "Num timesteps: 2000\n",
            "Best mean reward: -1190.72 - Last mean reward per step: -814.71\n",
            "Saving new best model to tmp2/best_model\n",
            "Num timesteps: 3000\n",
            "Best mean reward: -814.71 - Last mean reward per step: -723.19\n",
            "Saving new best model to tmp2/best_model\n",
            "Num timesteps: 4000\n",
            "Best mean reward: -723.19 - Last mean reward per step: -675.41\n",
            "Saving new best model to tmp2/best_model\n",
            "Num timesteps: 5000\n",
            "Best mean reward: -675.41 - Last mean reward per step: -634.51\n",
            "Saving new best model to tmp2/best_model\n",
            "Num timesteps: 6000\n",
            "Best mean reward: -634.51 - Last mean reward per step: -615.00\n",
            "Saving new best model to tmp2/best_model\n",
            "Num timesteps: 7000\n",
            "Best mean reward: -615.00 - Last mean reward per step: -613.09\n",
            "Saving new best model to tmp2/best_model\n",
            "Num timesteps: 8000\n",
            "Best mean reward: -613.09 - Last mean reward per step: -555.18\n",
            "Saving new best model to tmp2/best_model\n",
            "Num timesteps: 9000\n",
            "Best mean reward: -555.18 - Last mean reward per step: -565.76\n",
            "Num timesteps: 10000\n",
            "Best mean reward: -555.18 - Last mean reward per step: -565.49\n",
            "Num timesteps: 11000\n",
            "Best mean reward: -555.18 - Last mean reward per step: -572.68\n",
            "Num timesteps: 12000\n",
            "Best mean reward: -555.18 - Last mean reward per step: -575.26\n",
            "Num timesteps: 13000\n",
            "Best mean reward: -555.18 - Last mean reward per step: -579.70\n",
            "Num timesteps: 14000\n",
            "Best mean reward: -555.18 - Last mean reward per step: -569.37\n",
            "Num timesteps: 15000\n",
            "Best mean reward: -555.18 - Last mean reward per step: -567.19\n",
            "Num timesteps: 16000\n",
            "Best mean reward: -555.18 - Last mean reward per step: -567.42\n",
            "Num timesteps: 17000\n",
            "Best mean reward: -555.18 - Last mean reward per step: -566.59\n",
            "Num timesteps: 18000\n",
            "Best mean reward: -555.18 - Last mean reward per step: -566.56\n",
            "Num timesteps: 19000\n",
            "Best mean reward: -555.18 - Last mean reward per step: -586.38\n",
            "Num timesteps: 20000\n",
            "Best mean reward: -555.18 - Last mean reward per step: -577.59\n",
            "Num timesteps: 21000\n",
            "Best mean reward: -555.18 - Last mean reward per step: -569.39\n",
            "Num timesteps: 22000\n",
            "Best mean reward: -555.18 - Last mean reward per step: -563.51\n",
            "Num timesteps: 23000\n",
            "Best mean reward: -555.18 - Last mean reward per step: -558.81\n",
            "Num timesteps: 24000\n",
            "Best mean reward: -555.18 - Last mean reward per step: -554.02\n",
            "Saving new best model to tmp2/best_model\n",
            "Num timesteps: 25000\n",
            "Best mean reward: -554.02 - Last mean reward per step: -567.10\n",
            "Num timesteps: 26000\n",
            "Best mean reward: -554.02 - Last mean reward per step: -552.69\n",
            "Saving new best model to tmp2/best_model\n",
            "Num timesteps: 27000\n",
            "Best mean reward: -552.69 - Last mean reward per step: -552.38\n",
            "Saving new best model to tmp2/best_model\n",
            "Num timesteps: 28000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -568.14\n",
            "Num timesteps: 29000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -567.78\n",
            "Num timesteps: 30000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -561.17\n",
            "Num timesteps: 31000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -562.43\n",
            "Num timesteps: 32000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -560.97\n",
            "Num timesteps: 33000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -563.22\n",
            "Num timesteps: 34000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -578.67\n",
            "Num timesteps: 35000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -556.30\n",
            "Num timesteps: 36000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -567.62\n",
            "Num timesteps: 37000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -566.03\n",
            "Num timesteps: 38000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -571.83\n",
            "Num timesteps: 39000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -572.92\n",
            "Num timesteps: 40000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -566.78\n",
            "Num timesteps: 41000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -572.84\n",
            "Num timesteps: 42000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -585.86\n",
            "Num timesteps: 43000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -573.59\n",
            "Num timesteps: 44000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -569.45\n",
            "Num timesteps: 45000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -568.65\n",
            "Num timesteps: 46000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -565.64\n",
            "Num timesteps: 47000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -562.87\n",
            "Num timesteps: 48000\n",
            "Best mean reward: -552.38 - Last mean reward per step: -545.80\n",
            "Saving new best model to tmp2/best_model\n",
            "Num timesteps: 49000\n",
            "Best mean reward: -545.80 - Last mean reward per step: -544.88\n",
            "Saving new best model to tmp2/best_model\n",
            "Num timesteps: 50000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -550.20\n",
            "Num timesteps: 51000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -555.84\n",
            "Num timesteps: 52000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -564.18\n",
            "Num timesteps: 53000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -575.41\n",
            "Num timesteps: 54000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -569.58\n",
            "Num timesteps: 55000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -571.49\n",
            "Num timesteps: 56000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -584.70\n",
            "Num timesteps: 57000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -580.62\n",
            "Num timesteps: 58000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -581.08\n",
            "Num timesteps: 59000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -577.64\n",
            "Num timesteps: 60000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -570.28\n",
            "Num timesteps: 61000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -581.31\n",
            "Num timesteps: 62000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -581.60\n",
            "Num timesteps: 63000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -562.31\n",
            "Num timesteps: 64000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -558.59\n",
            "Num timesteps: 65000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -567.87\n",
            "Num timesteps: 66000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -565.49\n",
            "Num timesteps: 67000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -545.64\n",
            "Num timesteps: 68000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -553.08\n",
            "Num timesteps: 69000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -557.59\n",
            "Num timesteps: 70000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -557.75\n",
            "Num timesteps: 71000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -562.29\n",
            "Num timesteps: 72000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -551.41\n",
            "Num timesteps: 73000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -558.66\n",
            "Num timesteps: 74000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -568.30\n",
            "Num timesteps: 75000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -566.97\n",
            "Num timesteps: 76000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -565.32\n",
            "Num timesteps: 77000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -564.03\n",
            "Num timesteps: 78000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -566.74\n",
            "Num timesteps: 79000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -559.08\n",
            "Num timesteps: 80000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -556.76\n",
            "Num timesteps: 81000\n",
            "Best mean reward: -544.88 - Last mean reward per step: -543.03\n",
            "Saving new best model to tmp2/best_model\n",
            "Num timesteps: 82000\n",
            "Best mean reward: -543.03 - Last mean reward per step: -547.77\n",
            "Num timesteps: 83000\n",
            "Best mean reward: -543.03 - Last mean reward per step: -544.54\n",
            "Num timesteps: 84000\n",
            "Best mean reward: -543.03 - Last mean reward per step: -545.27\n",
            "Num timesteps: 85000\n",
            "Best mean reward: -543.03 - Last mean reward per step: -545.75\n",
            "Num timesteps: 86000\n",
            "Best mean reward: -543.03 - Last mean reward per step: -550.78\n",
            "Num timesteps: 87000\n",
            "Best mean reward: -543.03 - Last mean reward per step: -546.92\n",
            "Num timesteps: 88000\n",
            "Best mean reward: -543.03 - Last mean reward per step: -560.87\n",
            "Num timesteps: 89000\n",
            "Best mean reward: -543.03 - Last mean reward per step: -566.58\n",
            "Num timesteps: 90000\n",
            "Best mean reward: -543.03 - Last mean reward per step: -562.75\n",
            "Num timesteps: 91000\n",
            "Best mean reward: -543.03 - Last mean reward per step: -559.79\n",
            "Num timesteps: 92000\n",
            "Best mean reward: -543.03 - Last mean reward per step: -569.34\n",
            "Num timesteps: 93000\n",
            "Best mean reward: -543.03 - Last mean reward per step: -577.15\n",
            "Num timesteps: 94000\n",
            "Best mean reward: -543.03 - Last mean reward per step: -579.97\n",
            "Num timesteps: 95000\n",
            "Best mean reward: -543.03 - Last mean reward per step: -574.74\n",
            "Num timesteps: 96000\n",
            "Best mean reward: -543.03 - Last mean reward per step: -569.49\n",
            "Num timesteps: 97000\n",
            "Best mean reward: -543.03 - Last mean reward per step: -576.31\n",
            "Num timesteps: 98000\n",
            "Best mean reward: -543.03 - Last mean reward per step: -578.30\n",
            "Num timesteps: 99000\n",
            "Best mean reward: -543.03 - Last mean reward per step: -582.59\n",
            "Num timesteps: 100000\n",
            "Best mean reward: -543.03 - Last mean reward per step: -575.69\n",
            "Les résultats de l'entraînement pour seed=2 ont été enregistrés dans training_results_seed2.json.\n",
            "Num timesteps: 1000\n",
            "Best mean reward: -inf - Last mean reward per step: -491.69\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 2000\n",
            "Best mean reward: -491.69 - Last mean reward per step: -494.34\n",
            "Num timesteps: 3000\n",
            "Best mean reward: -491.69 - Last mean reward per step: -453.40\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 4000\n",
            "Best mean reward: -453.40 - Last mean reward per step: -397.65\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 5000\n",
            "Best mean reward: -397.65 - Last mean reward per step: -345.92\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 6000\n",
            "Best mean reward: -345.92 - Last mean reward per step: -340.16\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 7000\n",
            "Best mean reward: -340.16 - Last mean reward per step: -330.30\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 8000\n",
            "Best mean reward: -330.30 - Last mean reward per step: -318.74\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 9000\n",
            "Best mean reward: -318.74 - Last mean reward per step: -285.56\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 10000\n",
            "Best mean reward: -285.56 - Last mean reward per step: -277.29\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 11000\n",
            "Best mean reward: -277.29 - Last mean reward per step: -271.11\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 12000\n",
            "Best mean reward: -271.11 - Last mean reward per step: -267.77\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 13000\n",
            "Best mean reward: -267.77 - Last mean reward per step: -261.52\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 14000\n",
            "Best mean reward: -261.52 - Last mean reward per step: -257.53\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 15000\n",
            "Best mean reward: -257.53 - Last mean reward per step: -251.85\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 16000\n",
            "Best mean reward: -251.85 - Last mean reward per step: -248.80\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 17000\n",
            "Best mean reward: -248.80 - Last mean reward per step: -246.21\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 18000\n",
            "Best mean reward: -246.21 - Last mean reward per step: -242.35\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 19000\n",
            "Best mean reward: -242.35 - Last mean reward per step: -234.22\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 20000\n",
            "Best mean reward: -234.22 - Last mean reward per step: -221.04\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 21000\n",
            "Best mean reward: -221.04 - Last mean reward per step: -215.97\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 22000\n",
            "Best mean reward: -215.97 - Last mean reward per step: -203.15\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 23000\n",
            "Best mean reward: -203.15 - Last mean reward per step: -196.49\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 24000\n",
            "Best mean reward: -196.49 - Last mean reward per step: -198.09\n",
            "Num timesteps: 25000\n",
            "Best mean reward: -196.49 - Last mean reward per step: -194.20\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 26000\n",
            "Best mean reward: -194.20 - Last mean reward per step: -200.92\n",
            "Num timesteps: 27000\n",
            "Best mean reward: -194.20 - Last mean reward per step: -197.65\n",
            "Num timesteps: 28000\n",
            "Best mean reward: -194.20 - Last mean reward per step: -194.02\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 29000\n",
            "Best mean reward: -194.02 - Last mean reward per step: -191.54\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 30000\n",
            "Best mean reward: -191.54 - Last mean reward per step: -191.60\n",
            "Num timesteps: 31000\n",
            "Best mean reward: -191.54 - Last mean reward per step: -189.71\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 32000\n",
            "Best mean reward: -189.71 - Last mean reward per step: -186.74\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 33000\n",
            "Best mean reward: -186.74 - Last mean reward per step: -187.91\n",
            "Num timesteps: 34000\n",
            "Best mean reward: -186.74 - Last mean reward per step: -190.23\n",
            "Num timesteps: 35000\n",
            "Best mean reward: -186.74 - Last mean reward per step: -187.92\n",
            "Num timesteps: 36000\n",
            "Best mean reward: -186.74 - Last mean reward per step: -187.30\n",
            "Num timesteps: 37000\n",
            "Best mean reward: -186.74 - Last mean reward per step: -182.88\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 38000\n",
            "Best mean reward: -182.88 - Last mean reward per step: -177.97\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 39000\n",
            "Best mean reward: -177.97 - Last mean reward per step: -154.24\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 40000\n",
            "Best mean reward: -154.24 - Last mean reward per step: -153.85\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 41000\n",
            "Best mean reward: -153.85 - Last mean reward per step: -152.34\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 42000\n",
            "Best mean reward: -152.34 - Last mean reward per step: -153.41\n",
            "Num timesteps: 43000\n",
            "Best mean reward: -152.34 - Last mean reward per step: -152.27\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 44000\n",
            "Best mean reward: -152.27 - Last mean reward per step: -152.17\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 45000\n",
            "Best mean reward: -152.17 - Last mean reward per step: -151.91\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 46000\n",
            "Best mean reward: -151.91 - Last mean reward per step: -151.43\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 47000\n",
            "Best mean reward: -151.43 - Last mean reward per step: -150.01\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 48000\n",
            "Best mean reward: -150.01 - Last mean reward per step: -149.30\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 49000\n",
            "Best mean reward: -149.30 - Last mean reward per step: -146.56\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 50000\n",
            "Best mean reward: -146.56 - Last mean reward per step: -145.06\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 51000\n",
            "Best mean reward: -145.06 - Last mean reward per step: -144.21\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 52000\n",
            "Best mean reward: -144.21 - Last mean reward per step: -144.21\n",
            "Num timesteps: 53000\n",
            "Best mean reward: -144.21 - Last mean reward per step: -143.52\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 54000\n",
            "Best mean reward: -143.52 - Last mean reward per step: -144.03\n",
            "Num timesteps: 55000\n",
            "Best mean reward: -143.52 - Last mean reward per step: -143.07\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 56000\n",
            "Best mean reward: -143.07 - Last mean reward per step: -142.39\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 57000\n",
            "Best mean reward: -142.39 - Last mean reward per step: -141.41\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 58000\n",
            "Best mean reward: -141.41 - Last mean reward per step: -137.97\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 59000\n",
            "Best mean reward: -137.97 - Last mean reward per step: -136.74\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 60000\n",
            "Best mean reward: -136.74 - Last mean reward per step: -132.19\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 61000\n",
            "Best mean reward: -132.19 - Last mean reward per step: -132.80\n",
            "Num timesteps: 62000\n",
            "Best mean reward: -132.19 - Last mean reward per step: -132.40\n",
            "Num timesteps: 63000\n",
            "Best mean reward: -132.19 - Last mean reward per step: -126.96\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 64000\n",
            "Best mean reward: -126.96 - Last mean reward per step: -126.07\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 65000\n",
            "Best mean reward: -126.07 - Last mean reward per step: -126.20\n",
            "Num timesteps: 66000\n",
            "Best mean reward: -126.07 - Last mean reward per step: -125.87\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 67000\n",
            "Best mean reward: -125.87 - Last mean reward per step: -124.01\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 68000\n",
            "Best mean reward: -124.01 - Last mean reward per step: -124.39\n",
            "Num timesteps: 69000\n",
            "Best mean reward: -124.01 - Last mean reward per step: -124.57\n",
            "Num timesteps: 70000\n",
            "Best mean reward: -124.01 - Last mean reward per step: -123.95\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 71000\n",
            "Best mean reward: -123.95 - Last mean reward per step: -122.97\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 72000\n",
            "Best mean reward: -122.97 - Last mean reward per step: -124.01\n",
            "Num timesteps: 73000\n",
            "Best mean reward: -122.97 - Last mean reward per step: -124.81\n",
            "Num timesteps: 74000\n",
            "Best mean reward: -122.97 - Last mean reward per step: -123.43\n",
            "Num timesteps: 75000\n",
            "Best mean reward: -122.97 - Last mean reward per step: -121.63\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 76000\n",
            "Best mean reward: -121.63 - Last mean reward per step: -121.15\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 77000\n",
            "Best mean reward: -121.15 - Last mean reward per step: -123.77\n",
            "Num timesteps: 78000\n",
            "Best mean reward: -121.15 - Last mean reward per step: -122.77\n",
            "Num timesteps: 79000\n",
            "Best mean reward: -121.15 - Last mean reward per step: -123.05\n",
            "Num timesteps: 80000\n",
            "Best mean reward: -121.15 - Last mean reward per step: -122.97\n",
            "Num timesteps: 81000\n",
            "Best mean reward: -121.15 - Last mean reward per step: -122.40\n",
            "Num timesteps: 82000\n",
            "Best mean reward: -121.15 - Last mean reward per step: -119.61\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 83000\n",
            "Best mean reward: -119.61 - Last mean reward per step: -118.33\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 84000\n",
            "Best mean reward: -118.33 - Last mean reward per step: -116.50\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 85000\n",
            "Best mean reward: -116.50 - Last mean reward per step: -111.16\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 86000\n",
            "Best mean reward: -111.16 - Last mean reward per step: -112.59\n",
            "Num timesteps: 87000\n",
            "Best mean reward: -111.16 - Last mean reward per step: -103.89\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 88000\n",
            "Best mean reward: -103.89 - Last mean reward per step: -94.14\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 89000\n",
            "Best mean reward: -94.14 - Last mean reward per step: -94.65\n",
            "Num timesteps: 90000\n",
            "Best mean reward: -94.14 - Last mean reward per step: -95.41\n",
            "Num timesteps: 91000\n",
            "Best mean reward: -94.14 - Last mean reward per step: -91.81\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 92000\n",
            "Best mean reward: -91.81 - Last mean reward per step: -90.43\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 93000\n",
            "Best mean reward: -90.43 - Last mean reward per step: -81.59\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 94000\n",
            "Best mean reward: -81.59 - Last mean reward per step: -74.73\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 95000\n",
            "Best mean reward: -74.73 - Last mean reward per step: -65.38\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 96000\n",
            "Best mean reward: -65.38 - Last mean reward per step: -60.64\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 97000\n",
            "Best mean reward: -60.64 - Last mean reward per step: -58.06\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 98000\n",
            "Best mean reward: -58.06 - Last mean reward per step: -53.27\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 99000\n",
            "Best mean reward: -53.27 - Last mean reward per step: -47.96\n",
            "Saving new best model to tmp3/best_model\n",
            "Num timesteps: 100000\n",
            "Best mean reward: -47.96 - Last mean reward per step: -43.09\n",
            "Saving new best model to tmp3/best_model\n",
            "Les résultats de l'entraînement pour seed=3 ont été enregistrés dans training_results_seed3.json.\n",
            "Num timesteps: 1000\n",
            "Best mean reward: -inf - Last mean reward per step: -697.09\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 2000\n",
            "Best mean reward: -697.09 - Last mean reward per step: -766.24\n",
            "Num timesteps: 3000\n",
            "Best mean reward: -697.09 - Last mean reward per step: -734.31\n",
            "Num timesteps: 4000\n",
            "Best mean reward: -697.09 - Last mean reward per step: -715.51\n",
            "Num timesteps: 5000\n",
            "Best mean reward: -697.09 - Last mean reward per step: -734.68\n",
            "Num timesteps: 6000\n",
            "Best mean reward: -697.09 - Last mean reward per step: -745.44\n",
            "Num timesteps: 7000\n",
            "Best mean reward: -697.09 - Last mean reward per step: -766.20\n",
            "Num timesteps: 8000\n",
            "Best mean reward: -697.09 - Last mean reward per step: -781.09\n",
            "Num timesteps: 9000\n",
            "Best mean reward: -697.09 - Last mean reward per step: -796.33\n",
            "Num timesteps: 10000\n",
            "Best mean reward: -697.09 - Last mean reward per step: -803.84\n",
            "Num timesteps: 11000\n",
            "Best mean reward: -697.09 - Last mean reward per step: -822.33\n",
            "Num timesteps: 12000\n",
            "Best mean reward: -697.09 - Last mean reward per step: -797.26\n",
            "Num timesteps: 13000\n",
            "Best mean reward: -697.09 - Last mean reward per step: -776.88\n",
            "Num timesteps: 14000\n",
            "Best mean reward: -697.09 - Last mean reward per step: -760.74\n",
            "Num timesteps: 15000\n",
            "Best mean reward: -697.09 - Last mean reward per step: -748.09\n",
            "Num timesteps: 16000\n",
            "Best mean reward: -697.09 - Last mean reward per step: -729.41\n",
            "Num timesteps: 17000\n",
            "Best mean reward: -697.09 - Last mean reward per step: -713.75\n",
            "Num timesteps: 18000\n",
            "Best mean reward: -697.09 - Last mean reward per step: -671.32\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 19000\n",
            "Best mean reward: -671.32 - Last mean reward per step: -637.84\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 20000\n",
            "Best mean reward: -637.84 - Last mean reward per step: -609.55\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 21000\n",
            "Best mean reward: -609.55 - Last mean reward per step: -573.07\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 22000\n",
            "Best mean reward: -573.07 - Last mean reward per step: -545.75\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 23000\n",
            "Best mean reward: -545.75 - Last mean reward per step: -502.65\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 24000\n",
            "Best mean reward: -502.65 - Last mean reward per step: -460.48\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 25000\n",
            "Best mean reward: -460.48 - Last mean reward per step: -429.39\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 26000\n",
            "Best mean reward: -429.39 - Last mean reward per step: -408.36\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 27000\n",
            "Best mean reward: -408.36 - Last mean reward per step: -384.36\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 28000\n",
            "Best mean reward: -384.36 - Last mean reward per step: -354.47\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 29000\n",
            "Best mean reward: -354.47 - Last mean reward per step: -339.51\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 30000\n",
            "Best mean reward: -339.51 - Last mean reward per step: -315.87\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 31000\n",
            "Best mean reward: -315.87 - Last mean reward per step: -288.31\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 32000\n",
            "Best mean reward: -288.31 - Last mean reward per step: -272.98\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 33000\n",
            "Best mean reward: -272.98 - Last mean reward per step: -261.47\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 34000\n",
            "Best mean reward: -261.47 - Last mean reward per step: -256.06\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 35000\n",
            "Best mean reward: -256.06 - Last mean reward per step: -255.34\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 36000\n",
            "Best mean reward: -255.34 - Last mean reward per step: -255.00\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 37000\n",
            "Best mean reward: -255.00 - Last mean reward per step: -256.80\n",
            "Num timesteps: 38000\n",
            "Best mean reward: -255.00 - Last mean reward per step: -258.05\n",
            "Num timesteps: 39000\n",
            "Best mean reward: -255.00 - Last mean reward per step: -258.41\n",
            "Num timesteps: 40000\n",
            "Best mean reward: -255.00 - Last mean reward per step: -259.70\n",
            "Num timesteps: 41000\n",
            "Best mean reward: -255.00 - Last mean reward per step: -260.08\n",
            "Num timesteps: 42000\n",
            "Best mean reward: -255.00 - Last mean reward per step: -259.45\n",
            "Num timesteps: 43000\n",
            "Best mean reward: -255.00 - Last mean reward per step: -256.78\n",
            "Num timesteps: 44000\n",
            "Best mean reward: -255.00 - Last mean reward per step: -253.52\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 45000\n",
            "Best mean reward: -253.52 - Last mean reward per step: -250.93\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 46000\n",
            "Best mean reward: -250.93 - Last mean reward per step: -250.05\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 47000\n",
            "Best mean reward: -250.05 - Last mean reward per step: -248.31\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 48000\n",
            "Best mean reward: -248.31 - Last mean reward per step: -244.57\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 49000\n",
            "Best mean reward: -244.57 - Last mean reward per step: -245.25\n",
            "Num timesteps: 50000\n",
            "Best mean reward: -244.57 - Last mean reward per step: -244.34\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 51000\n",
            "Best mean reward: -244.34 - Last mean reward per step: -241.13\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 52000\n",
            "Best mean reward: -241.13 - Last mean reward per step: -240.67\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 53000\n",
            "Best mean reward: -240.67 - Last mean reward per step: -239.94\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 54000\n",
            "Best mean reward: -239.94 - Last mean reward per step: -240.95\n",
            "Num timesteps: 55000\n",
            "Best mean reward: -239.94 - Last mean reward per step: -239.74\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 56000\n",
            "Best mean reward: -239.74 - Last mean reward per step: -236.68\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 57000\n",
            "Best mean reward: -236.68 - Last mean reward per step: -233.34\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 58000\n",
            "Best mean reward: -233.34 - Last mean reward per step: -230.60\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 59000\n",
            "Best mean reward: -230.60 - Last mean reward per step: -229.52\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 60000\n",
            "Best mean reward: -229.52 - Last mean reward per step: -226.86\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 61000\n",
            "Best mean reward: -226.86 - Last mean reward per step: -226.05\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 62000\n",
            "Best mean reward: -226.05 - Last mean reward per step: -225.33\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 63000\n",
            "Best mean reward: -225.33 - Last mean reward per step: -225.17\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 64000\n",
            "Best mean reward: -225.17 - Last mean reward per step: -225.25\n",
            "Num timesteps: 65000\n",
            "Best mean reward: -225.17 - Last mean reward per step: -223.79\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 66000\n",
            "Best mean reward: -223.79 - Last mean reward per step: -220.69\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 67000\n",
            "Best mean reward: -220.69 - Last mean reward per step: -220.33\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 68000\n",
            "Best mean reward: -220.33 - Last mean reward per step: -217.74\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 69000\n",
            "Best mean reward: -217.74 - Last mean reward per step: -220.08\n",
            "Num timesteps: 70000\n",
            "Best mean reward: -217.74 - Last mean reward per step: -230.44\n",
            "Num timesteps: 71000\n",
            "Best mean reward: -217.74 - Last mean reward per step: -228.96\n",
            "Num timesteps: 72000\n",
            "Best mean reward: -217.74 - Last mean reward per step: -227.24\n",
            "Num timesteps: 73000\n",
            "Best mean reward: -217.74 - Last mean reward per step: -224.40\n",
            "Num timesteps: 74000\n",
            "Best mean reward: -217.74 - Last mean reward per step: -223.21\n",
            "Num timesteps: 75000\n",
            "Best mean reward: -217.74 - Last mean reward per step: -222.94\n",
            "Num timesteps: 76000\n",
            "Best mean reward: -217.74 - Last mean reward per step: -222.80\n",
            "Num timesteps: 77000\n",
            "Best mean reward: -217.74 - Last mean reward per step: -221.32\n",
            "Num timesteps: 78000\n",
            "Best mean reward: -217.74 - Last mean reward per step: -218.06\n",
            "Num timesteps: 79000\n",
            "Best mean reward: -217.74 - Last mean reward per step: -217.54\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 80000\n",
            "Best mean reward: -217.54 - Last mean reward per step: -215.90\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 81000\n",
            "Best mean reward: -215.90 - Last mean reward per step: -213.55\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 82000\n",
            "Best mean reward: -213.55 - Last mean reward per step: -212.48\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 83000\n",
            "Best mean reward: -212.48 - Last mean reward per step: -209.51\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 84000\n",
            "Best mean reward: -209.51 - Last mean reward per step: -209.00\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 85000\n",
            "Best mean reward: -209.00 - Last mean reward per step: -205.04\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 86000\n",
            "Best mean reward: -205.04 - Last mean reward per step: -204.00\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 87000\n",
            "Best mean reward: -204.00 - Last mean reward per step: -201.79\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 88000\n",
            "Best mean reward: -201.79 - Last mean reward per step: -200.20\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 89000\n",
            "Best mean reward: -200.20 - Last mean reward per step: -200.30\n",
            "Num timesteps: 90000\n",
            "Best mean reward: -200.20 - Last mean reward per step: -197.00\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 91000\n",
            "Best mean reward: -197.00 - Last mean reward per step: -195.55\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 92000\n",
            "Best mean reward: -195.55 - Last mean reward per step: -194.96\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 93000\n",
            "Best mean reward: -194.96 - Last mean reward per step: -193.35\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 94000\n",
            "Best mean reward: -193.35 - Last mean reward per step: -191.53\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 95000\n",
            "Best mean reward: -191.53 - Last mean reward per step: -191.84\n",
            "Num timesteps: 96000\n",
            "Best mean reward: -191.53 - Last mean reward per step: -189.26\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 97000\n",
            "Best mean reward: -189.26 - Last mean reward per step: -186.84\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 98000\n",
            "Best mean reward: -186.84 - Last mean reward per step: -184.66\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 99000\n",
            "Best mean reward: -184.66 - Last mean reward per step: -182.73\n",
            "Saving new best model to tmp4/best_model\n",
            "Num timesteps: 100000\n",
            "Best mean reward: -182.73 - Last mean reward per step: -178.33\n",
            "Saving new best model to tmp4/best_model\n",
            "Les résultats de l'entraînement pour seed=4 ont été enregistrés dans training_results_seed4.json.\n",
            "Num timesteps: 1000\n",
            "Best mean reward: -inf - Last mean reward per step: -593.68\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 2000\n",
            "Best mean reward: -593.68 - Last mean reward per step: -463.66\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 3000\n",
            "Best mean reward: -463.66 - Last mean reward per step: -324.22\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 4000\n",
            "Best mean reward: -324.22 - Last mean reward per step: -281.64\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 5000\n",
            "Best mean reward: -281.64 - Last mean reward per step: -257.84\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 6000\n",
            "Best mean reward: -257.84 - Last mean reward per step: -249.10\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 7000\n",
            "Best mean reward: -249.10 - Last mean reward per step: -239.16\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 8000\n",
            "Best mean reward: -239.16 - Last mean reward per step: -228.95\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 9000\n",
            "Best mean reward: -228.95 - Last mean reward per step: -227.12\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 10000\n",
            "Best mean reward: -227.12 - Last mean reward per step: -222.70\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 11000\n",
            "Best mean reward: -222.70 - Last mean reward per step: -219.44\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 12000\n",
            "Best mean reward: -219.44 - Last mean reward per step: -222.57\n",
            "Num timesteps: 13000\n",
            "Best mean reward: -219.44 - Last mean reward per step: -229.73\n",
            "Num timesteps: 14000\n",
            "Best mean reward: -219.44 - Last mean reward per step: -232.45\n",
            "Num timesteps: 15000\n",
            "Best mean reward: -219.44 - Last mean reward per step: -236.04\n",
            "Num timesteps: 16000\n",
            "Best mean reward: -219.44 - Last mean reward per step: -229.49\n",
            "Num timesteps: 17000\n",
            "Best mean reward: -219.44 - Last mean reward per step: -234.38\n",
            "Num timesteps: 18000\n",
            "Best mean reward: -219.44 - Last mean reward per step: -226.41\n",
            "Num timesteps: 19000\n",
            "Best mean reward: -219.44 - Last mean reward per step: -227.31\n",
            "Num timesteps: 20000\n",
            "Best mean reward: -219.44 - Last mean reward per step: -224.83\n",
            "Num timesteps: 21000\n",
            "Best mean reward: -219.44 - Last mean reward per step: -216.02\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 22000\n",
            "Best mean reward: -216.02 - Last mean reward per step: -212.89\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 23000\n",
            "Best mean reward: -212.89 - Last mean reward per step: -203.47\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 24000\n",
            "Best mean reward: -203.47 - Last mean reward per step: -198.87\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 25000\n",
            "Best mean reward: -198.87 - Last mean reward per step: -197.34\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 26000\n",
            "Best mean reward: -197.34 - Last mean reward per step: -198.32\n",
            "Num timesteps: 27000\n",
            "Best mean reward: -197.34 - Last mean reward per step: -196.36\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 28000\n",
            "Best mean reward: -196.36 - Last mean reward per step: -194.43\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 29000\n",
            "Best mean reward: -194.43 - Last mean reward per step: -192.10\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 30000\n",
            "Best mean reward: -192.10 - Last mean reward per step: -190.66\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 31000\n",
            "Best mean reward: -190.66 - Last mean reward per step: -189.44\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 32000\n",
            "Best mean reward: -189.44 - Last mean reward per step: -188.05\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 33000\n",
            "Best mean reward: -188.05 - Last mean reward per step: -182.65\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 34000\n",
            "Best mean reward: -182.65 - Last mean reward per step: -183.11\n",
            "Num timesteps: 35000\n",
            "Best mean reward: -182.65 - Last mean reward per step: -182.46\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 36000\n",
            "Best mean reward: -182.46 - Last mean reward per step: -181.79\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 37000\n",
            "Best mean reward: -181.79 - Last mean reward per step: -180.55\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 38000\n",
            "Best mean reward: -180.55 - Last mean reward per step: -179.38\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 39000\n",
            "Best mean reward: -179.38 - Last mean reward per step: -178.63\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 40000\n",
            "Best mean reward: -178.63 - Last mean reward per step: -162.53\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 41000\n",
            "Best mean reward: -162.53 - Last mean reward per step: -156.60\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 42000\n",
            "Best mean reward: -156.60 - Last mean reward per step: -140.88\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 43000\n",
            "Best mean reward: -140.88 - Last mean reward per step: -134.17\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 44000\n",
            "Best mean reward: -134.17 - Last mean reward per step: -127.27\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 45000\n",
            "Best mean reward: -127.27 - Last mean reward per step: -127.70\n",
            "Num timesteps: 46000\n",
            "Best mean reward: -127.27 - Last mean reward per step: -127.47\n",
            "Num timesteps: 47000\n",
            "Best mean reward: -127.27 - Last mean reward per step: -127.11\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 48000\n",
            "Best mean reward: -127.11 - Last mean reward per step: -121.91\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 49000\n",
            "Best mean reward: -121.91 - Last mean reward per step: -121.43\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 50000\n",
            "Best mean reward: -121.43 - Last mean reward per step: -121.47\n",
            "Num timesteps: 51000\n",
            "Best mean reward: -121.43 - Last mean reward per step: -119.45\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 52000\n",
            "Best mean reward: -119.45 - Last mean reward per step: -119.66\n",
            "Num timesteps: 53000\n",
            "Best mean reward: -119.45 - Last mean reward per step: -119.53\n",
            "Num timesteps: 54000\n",
            "Best mean reward: -119.45 - Last mean reward per step: -117.08\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 55000\n",
            "Best mean reward: -117.08 - Last mean reward per step: -116.97\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 56000\n",
            "Best mean reward: -116.97 - Last mean reward per step: -116.85\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 57000\n",
            "Best mean reward: -116.85 - Last mean reward per step: -114.81\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 58000\n",
            "Best mean reward: -114.81 - Last mean reward per step: -114.66\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 59000\n",
            "Best mean reward: -114.66 - Last mean reward per step: -114.44\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 60000\n",
            "Best mean reward: -114.44 - Last mean reward per step: -113.77\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 61000\n",
            "Best mean reward: -113.77 - Last mean reward per step: -112.12\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 62000\n",
            "Best mean reward: -112.12 - Last mean reward per step: -108.39\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 63000\n",
            "Best mean reward: -108.39 - Last mean reward per step: -106.99\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 64000\n",
            "Best mean reward: -106.99 - Last mean reward per step: -105.87\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 65000\n",
            "Best mean reward: -105.87 - Last mean reward per step: -104.99\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 66000\n",
            "Best mean reward: -104.99 - Last mean reward per step: -103.60\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 67000\n",
            "Best mean reward: -103.60 - Last mean reward per step: -103.47\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 68000\n",
            "Best mean reward: -103.47 - Last mean reward per step: -102.90\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 69000\n",
            "Best mean reward: -102.90 - Last mean reward per step: -102.65\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 70000\n",
            "Best mean reward: -102.65 - Last mean reward per step: -98.96\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 71000\n",
            "Best mean reward: -98.96 - Last mean reward per step: -97.44\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 72000\n",
            "Best mean reward: -97.44 - Last mean reward per step: -97.08\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 73000\n",
            "Best mean reward: -97.08 - Last mean reward per step: -93.57\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 74000\n",
            "Best mean reward: -93.57 - Last mean reward per step: -86.00\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 75000\n",
            "Best mean reward: -86.00 - Last mean reward per step: -83.37\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 76000\n",
            "Best mean reward: -83.37 - Last mean reward per step: -81.92\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 77000\n",
            "Best mean reward: -81.92 - Last mean reward per step: -77.02\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 78000\n",
            "Best mean reward: -77.02 - Last mean reward per step: -77.07\n",
            "Num timesteps: 79000\n",
            "Best mean reward: -77.02 - Last mean reward per step: -75.32\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 80000\n",
            "Best mean reward: -75.32 - Last mean reward per step: -74.38\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 81000\n",
            "Best mean reward: -74.38 - Last mean reward per step: -77.85\n",
            "Num timesteps: 82000\n",
            "Best mean reward: -74.38 - Last mean reward per step: -79.75\n",
            "Num timesteps: 83000\n",
            "Best mean reward: -74.38 - Last mean reward per step: -79.99\n",
            "Num timesteps: 84000\n",
            "Best mean reward: -74.38 - Last mean reward per step: -78.55\n",
            "Num timesteps: 85000\n",
            "Best mean reward: -74.38 - Last mean reward per step: -78.39\n",
            "Num timesteps: 86000\n",
            "Best mean reward: -74.38 - Last mean reward per step: -79.14\n",
            "Num timesteps: 87000\n",
            "Best mean reward: -74.38 - Last mean reward per step: -77.06\n",
            "Num timesteps: 88000\n",
            "Best mean reward: -74.38 - Last mean reward per step: -76.53\n",
            "Num timesteps: 89000\n",
            "Best mean reward: -74.38 - Last mean reward per step: -74.60\n",
            "Num timesteps: 90000\n",
            "Best mean reward: -74.38 - Last mean reward per step: -74.97\n",
            "Num timesteps: 91000\n",
            "Best mean reward: -74.38 - Last mean reward per step: -76.17\n",
            "Num timesteps: 92000\n",
            "Best mean reward: -74.38 - Last mean reward per step: -75.28\n",
            "Num timesteps: 93000\n",
            "Best mean reward: -74.38 - Last mean reward per step: -73.56\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 94000\n",
            "Best mean reward: -73.56 - Last mean reward per step: -73.54\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 95000\n",
            "Best mean reward: -73.54 - Last mean reward per step: -73.04\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 96000\n",
            "Best mean reward: -73.04 - Last mean reward per step: -71.75\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 97000\n",
            "Best mean reward: -71.75 - Last mean reward per step: -71.62\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 98000\n",
            "Best mean reward: -71.62 - Last mean reward per step: -63.21\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 99000\n",
            "Best mean reward: -63.21 - Last mean reward per step: -55.58\n",
            "Saving new best model to tmp5/best_model\n",
            "Num timesteps: 100000\n",
            "Best mean reward: -55.58 - Last mean reward per step: -52.17\n",
            "Saving new best model to tmp5/best_model\n",
            "Les résultats de l'entraînement pour seed=5 ont été enregistrés dans training_results_seed5.json.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_part2 = {}\n",
        "\n",
        "seeds = [6,7,8,9,10]\n",
        "callbacks = []\n",
        "log_dirs = []\n",
        "models = []\n",
        "\n",
        "for seed in seeds:\n",
        "    # Set log directory\n",
        "    log_dir = f\"tmp{seed}/\"\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "    # Create and wrap the environment\n",
        "    env = gym.make(\"LunarLanderContinuous-v2\")\n",
        "    env.reset(seed=seed)\n",
        "    env = Monitor(env, log_dir)\n",
        "\n",
        "    # Add action noise for exploration\n",
        "    n_actions = env.action_space.shape[-1]\n",
        "    action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
        "\n",
        "    # Initialize model\n",
        "    model = TD3(\"MlpPolicy\", env, action_noise=action_noise, verbose=0, device=\"cuda\")\n",
        "\n",
        "    # Create callback to save model and track losses\n",
        "    callback = SaveOnBestTrainingRewardCallback(check_freq=1000, log_dir=log_dir)\n",
        "\n",
        "    callbacks.append(callback)\n",
        "    log_dirs.append(log_dir)\n",
        "    models.append(model)\n",
        "\n",
        "    # Train the model\n",
        "    timesteps = 1e5\n",
        "    model.learn(total_timesteps=int(timesteps), callback=callback)\n",
        "\n",
        "    # Stocker les résultats de l'entraînement pour cette seed\n",
        "    results = {\n",
        "        \"actor_losses\": [float(loss) for loss in callback.actor_losses],\n",
        "        \"critic_losses\": [float(loss) for loss in callback.critic_losses],\n",
        "        \"rewards_per_step\": [float(reward) for reward in callback.rewards_per_step],\n",
        "    }\n",
        "\n",
        "    # Sauvegarde des résultats dans un fichier JSON après chaque seed\n",
        "    with open(f\"training_results_seed{seed}.json\", \"w\") as f:\n",
        "        json.dump(results, f, indent=4)\n",
        "\n",
        "    print(f\"Les résultats de l'entraînement pour seed={seed} ont été enregistrés dans training_results_seed{seed}.json.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T45iy6mKIJ8k",
        "outputId": "2aba9d89-f321-4d24-d146-604585e03cc6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num timesteps: 1000\n",
            "Best mean reward: -inf - Last mean reward per step: -783.99\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 2000\n",
            "Best mean reward: -783.99 - Last mean reward per step: -688.45\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 3000\n",
            "Best mean reward: -688.45 - Last mean reward per step: -599.44\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 4000\n",
            "Best mean reward: -599.44 - Last mean reward per step: -585.61\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 5000\n",
            "Best mean reward: -585.61 - Last mean reward per step: -541.33\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 6000\n",
            "Best mean reward: -541.33 - Last mean reward per step: -490.16\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 7000\n",
            "Best mean reward: -490.16 - Last mean reward per step: -458.31\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 8000\n",
            "Best mean reward: -458.31 - Last mean reward per step: -441.28\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 9000\n",
            "Best mean reward: -441.28 - Last mean reward per step: -433.18\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 10000\n",
            "Best mean reward: -433.18 - Last mean reward per step: -426.08\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 11000\n",
            "Best mean reward: -426.08 - Last mean reward per step: -402.73\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 12000\n",
            "Best mean reward: -402.73 - Last mean reward per step: -388.56\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 13000\n",
            "Best mean reward: -388.56 - Last mean reward per step: -382.16\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 14000\n",
            "Best mean reward: -382.16 - Last mean reward per step: -372.74\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 15000\n",
            "Best mean reward: -372.74 - Last mean reward per step: -362.51\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 16000\n",
            "Best mean reward: -362.51 - Last mean reward per step: -359.79\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 17000\n",
            "Best mean reward: -359.79 - Last mean reward per step: -347.73\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 18000\n",
            "Best mean reward: -347.73 - Last mean reward per step: -343.17\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 19000\n",
            "Best mean reward: -343.17 - Last mean reward per step: -336.09\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 20000\n",
            "Best mean reward: -336.09 - Last mean reward per step: -326.13\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 21000\n",
            "Best mean reward: -326.13 - Last mean reward per step: -321.18\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 22000\n",
            "Best mean reward: -321.18 - Last mean reward per step: -317.59\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 23000\n",
            "Best mean reward: -317.59 - Last mean reward per step: -315.00\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 24000\n",
            "Best mean reward: -315.00 - Last mean reward per step: -311.07\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 25000\n",
            "Best mean reward: -311.07 - Last mean reward per step: -309.91\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 26000\n",
            "Best mean reward: -309.91 - Last mean reward per step: -303.75\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 27000\n",
            "Best mean reward: -303.75 - Last mean reward per step: -300.67\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 28000\n",
            "Best mean reward: -300.67 - Last mean reward per step: -298.22\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 29000\n",
            "Best mean reward: -298.22 - Last mean reward per step: -293.49\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 30000\n",
            "Best mean reward: -293.49 - Last mean reward per step: -293.61\n",
            "Num timesteps: 31000\n",
            "Best mean reward: -293.49 - Last mean reward per step: -290.90\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 32000\n",
            "Best mean reward: -290.90 - Last mean reward per step: -287.34\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 33000\n",
            "Best mean reward: -287.34 - Last mean reward per step: -284.70\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 34000\n",
            "Best mean reward: -284.70 - Last mean reward per step: -281.90\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 35000\n",
            "Best mean reward: -281.90 - Last mean reward per step: -279.03\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 36000\n",
            "Best mean reward: -279.03 - Last mean reward per step: -276.95\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 37000\n",
            "Best mean reward: -276.95 - Last mean reward per step: -273.25\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 38000\n",
            "Best mean reward: -273.25 - Last mean reward per step: -270.38\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 39000\n",
            "Best mean reward: -270.38 - Last mean reward per step: -268.37\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 40000\n",
            "Best mean reward: -268.37 - Last mean reward per step: -263.61\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 41000\n",
            "Best mean reward: -263.61 - Last mean reward per step: -262.13\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 42000\n",
            "Best mean reward: -262.13 - Last mean reward per step: -258.88\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 43000\n",
            "Best mean reward: -258.88 - Last mean reward per step: -257.57\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 44000\n",
            "Best mean reward: -257.57 - Last mean reward per step: -247.54\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 45000\n",
            "Best mean reward: -247.54 - Last mean reward per step: -243.54\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 46000\n",
            "Best mean reward: -243.54 - Last mean reward per step: -212.47\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 47000\n",
            "Best mean reward: -212.47 - Last mean reward per step: -201.85\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 48000\n",
            "Best mean reward: -201.85 - Last mean reward per step: -195.59\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 49000\n",
            "Best mean reward: -195.59 - Last mean reward per step: -187.99\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 50000\n",
            "Best mean reward: -187.99 - Last mean reward per step: -183.98\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 51000\n",
            "Best mean reward: -183.98 - Last mean reward per step: -180.40\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 52000\n",
            "Best mean reward: -180.40 - Last mean reward per step: -174.33\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 53000\n",
            "Best mean reward: -174.33 - Last mean reward per step: -165.81\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 54000\n",
            "Best mean reward: -165.81 - Last mean reward per step: -153.02\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 55000\n",
            "Best mean reward: -153.02 - Last mean reward per step: -138.26\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 56000\n",
            "Best mean reward: -138.26 - Last mean reward per step: -130.88\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 57000\n",
            "Best mean reward: -130.88 - Last mean reward per step: -125.38\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 58000\n",
            "Best mean reward: -125.38 - Last mean reward per step: -116.97\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 59000\n",
            "Best mean reward: -116.97 - Last mean reward per step: -110.84\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 60000\n",
            "Best mean reward: -110.84 - Last mean reward per step: -99.64\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 61000\n",
            "Best mean reward: -99.64 - Last mean reward per step: -90.60\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 62000\n",
            "Best mean reward: -90.60 - Last mean reward per step: -90.87\n",
            "Num timesteps: 63000\n",
            "Best mean reward: -90.60 - Last mean reward per step: -83.99\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 64000\n",
            "Best mean reward: -83.99 - Last mean reward per step: -80.85\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 65000\n",
            "Best mean reward: -80.85 - Last mean reward per step: -76.55\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 66000\n",
            "Best mean reward: -76.55 - Last mean reward per step: -75.24\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 67000\n",
            "Best mean reward: -75.24 - Last mean reward per step: -69.20\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 68000\n",
            "Best mean reward: -69.20 - Last mean reward per step: -63.43\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 69000\n",
            "Best mean reward: -63.43 - Last mean reward per step: -63.40\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 70000\n",
            "Best mean reward: -63.40 - Last mean reward per step: -63.09\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 71000\n",
            "Best mean reward: -63.09 - Last mean reward per step: -52.73\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 72000\n",
            "Best mean reward: -52.73 - Last mean reward per step: -49.06\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 73000\n",
            "Best mean reward: -49.06 - Last mean reward per step: -43.57\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 74000\n",
            "Best mean reward: -43.57 - Last mean reward per step: -35.14\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 75000\n",
            "Best mean reward: -35.14 - Last mean reward per step: -27.06\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 76000\n",
            "Best mean reward: -27.06 - Last mean reward per step: -25.82\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 77000\n",
            "Best mean reward: -25.82 - Last mean reward per step: -25.40\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 78000\n",
            "Best mean reward: -25.40 - Last mean reward per step: -24.26\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 79000\n",
            "Best mean reward: -24.26 - Last mean reward per step: -22.96\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 80000\n",
            "Best mean reward: -22.96 - Last mean reward per step: -19.06\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 81000\n",
            "Best mean reward: -19.06 - Last mean reward per step: -18.50\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 82000\n",
            "Best mean reward: -18.50 - Last mean reward per step: -14.20\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 83000\n",
            "Best mean reward: -14.20 - Last mean reward per step: -8.61\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 84000\n",
            "Best mean reward: -8.61 - Last mean reward per step: -8.90\n",
            "Num timesteps: 85000\n",
            "Best mean reward: -8.61 - Last mean reward per step: -1.08\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 86000\n",
            "Best mean reward: -1.08 - Last mean reward per step: 10.68\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 87000\n",
            "Best mean reward: 10.68 - Last mean reward per step: 12.14\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 88000\n",
            "Best mean reward: 12.14 - Last mean reward per step: 19.76\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 89000\n",
            "Best mean reward: 19.76 - Last mean reward per step: 24.78\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 90000\n",
            "Best mean reward: 24.78 - Last mean reward per step: 32.93\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 91000\n",
            "Best mean reward: 32.93 - Last mean reward per step: 42.37\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 92000\n",
            "Best mean reward: 42.37 - Last mean reward per step: 50.54\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 93000\n",
            "Best mean reward: 50.54 - Last mean reward per step: 58.90\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 94000\n",
            "Best mean reward: 58.90 - Last mean reward per step: 68.41\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 95000\n",
            "Best mean reward: 68.41 - Last mean reward per step: 69.58\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 96000\n",
            "Best mean reward: 69.58 - Last mean reward per step: 74.71\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 97000\n",
            "Best mean reward: 74.71 - Last mean reward per step: 85.65\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 98000\n",
            "Best mean reward: 85.65 - Last mean reward per step: 93.11\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 99000\n",
            "Best mean reward: 93.11 - Last mean reward per step: 98.67\n",
            "Saving new best model to tmp10/best_model\n",
            "Num timesteps: 100000\n",
            "Best mean reward: 98.67 - Last mean reward per step: 110.76\n",
            "Saving new best model to tmp10/best_model\n",
            "Les résultats de l'entraînement pour seed=10 ont été enregistrés dans training_results_seed10.json.\n"
          ]
        }
      ]
    }
  ]
}